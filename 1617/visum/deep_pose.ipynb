{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Pose Estimation\n",
    "====================\n",
    "\n",
    "The goal of this practical is to learn how to use Deep Learning to predict poses from images. For simplicity, we will focus on synthetic images and 2d poses of simple shapes, however the principles remain the same. In fact, for a new research problem, it is always a good idea to start with a toy problem: On the long term, it saves time.\n",
    "\n",
    "We will use TensorFlow. You can access a tutorial on TensorFlow [there](https://www.labri.fr/perso/vlepetit/teaching/visum/tensorflow.pdf) to get you started. The official [TensorFlow website](tensorflow.org/) (and Internet in general :-) ) provides more detailed information.\n",
    "\n",
    "We will start with a simple problem with rectangles oriented hozontally and vertically. For this problem, linear regression is enough to get good performance. For the second problem, we will consider rotating triangles, for which we will need a deep network.\n",
    "\n",
    "Imports\n",
    "-------\n",
    "\n",
    "The main libraries we will use are TensorFlow, NumPy, and Matplotlib for drawing images. Our code will therefore start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line\n",
    "```\n",
    "%matplotlib inline\n",
    "```\n",
    "is useful only in Jupyter notebooks to visualize the images online.\n",
    "\n",
    "Creating the data\n",
    "----------------\n",
    "\n",
    "The function below generates an image of a rectangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_rectangle(figsize, top, left, bottom, right, noise = 0):\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.axis('Off')\n",
    "    ax.set_xlim(0,figsize)\n",
    "    ax.set_ylim(0,figsize)\n",
    "    ax.fill((top, top, bottom, bottom), (left, right, right, left), \"k\")\n",
    "    fig.canvas.draw()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')[::3].astype(np.float32)\n",
    "    plt.close(fig)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand this function. You will see that it returns the image as a vector of 72x72=5184 values. We can test it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10fd14a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC5dJREFUeJzt3W+IZYV5x/Hvr7tK2qSyMa4irnYVxOgb13RIFUtptVts\nKpoXMShpCUHwTVqUpqSad4UWzJvEvCgBUVNf2Kg1kYoEUzFKWygb12ib6Go1dquDxl0bxTSFlE2e\nvrjHZmpn3bM7996ZO8/3A8Pcc+YO5xyv3/tvz50nVYWkXn5hvXdA0vwZvtSQ4UsNGb7UkOFLDRm+\n1JDhSw2tKfwklyV5LskLSW6c1k5Jmq0c6wk8SbYA/wrsBpaBx4FrquqZ6e2epFnYuobf/TDwQlW9\nCJDkbuBK4LDhn3TSSbVz5841bFLSu9m/fz+vv/56jnS9tYR/GvDyiuVl4Nfe7Rd27tzJ3r1717BJ\nSe9maWlp1PXW8hp/tXuV//e6Icl1SfYm2Xvw4ME1bE7StKwl/GXg9BXLO4BX3nmlqrq1qpaqamn7\n9u1r2JykaVlL+I8DZyc5M8nxwNXAA9PZLUmzdMyv8avqUJI/BL4JbAHuqKqnp7ZnkmZmLW/uUVXf\nAL4xpX2RNCeeuSc1ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhS\nQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNXTE8JPckeRAku+tWHdikoeTPD98f/9sd1PSNI15xP8r\n4LJ3rLsReKSqzgYeGZYlLYgjhl9Vfw/88B2rrwTuHC7fCXx0yvslaYaO9TX+KVX1KsDw/eTp7ZKk\nWZv5m3tOy5U2nmMN/7UkpwIM3w8c7opOy5U2nmMN/wHgk8PlTwJ/O53dkTQPY/4576vAPwHnJFlO\nci1wM7A7yfPA7mFZ0oI44rTcqrrmMD+6dMr7ImlOPHNPasjwpYYMX2rI8KWGDF9qyPClhgxfasjw\npYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGxvxd/dOT\nPJpkX5Knk1w/rHdUtrSgxjziHwI+U1XnAhcCn05yHo7KlhbWmDHZr1bVd4bLPwL2AafhqGxpYR3V\na/wkO4ELgD2MHJXttFxp4xkdfpL3AV8Dbqiqt8b+ntNypY1nVPhJjmMS/V1V9fVh9ehR2ZI2ljHv\n6ge4HdhXVV9Y8SNHZUsL6ojTcoGLgT8AvpvkqWHd55iMxr53GJv9EnDVbHZR0rSNGZP9j0AO82NH\nZUsLyDP3pIYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWG\nDF9qyPClhgxfasjwpYYMX2rI8KWGxvxd/fck+XaSfx6m5f7ZsP7MJHuGabn3JDl+9rsraRrGPOL/\nBLikqs4HdgGXJbkQ+DzwxWFa7hvAtbPbTUnTNGZablXVfw6Lxw1fBVwC3Desd1ruBpZk3b+0sYyd\nnbdlmKJzAHgY+D7wZlUdGq6yzGR09mq/67RcaYMZFX5V/bSqdgE7gA8D5652tcP8rtNypQ3mqN7V\nr6o3gceAC4FtSd4ewbUDeGW6uyZpVsa8q789ybbh8i8Cvw3sAx4FPjZczWm50gIZMy33VODOJFuY\n3FHcW1UPJnkGuDvJnwNPMhmlLWkBjJmW+y/ABausf5HJ631JC8Yz96SGDF9qyPClhgxfasjwpYYM\nX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhkaH\nP4zRejLJg8Oy03KlBXU0j/jXMxmk8Tan5UoLauzQzB3A7wG3DcvBabnSwhr7iH8L8FngZ8PyBxg5\nLVfSxjNmdt7lwIGqemLl6lWuuuq0XMdkSxvPmNl5FwNXJPkI8B7gBCbPALYl2To86h92Wm5V3Qrc\nCrC0tLTqnYNmq8r/7Pq/jviIX1U3VdWOqtoJXA18q6o+gdNypYW1ln/H/1Pgj5O8wOQ1v9NypQUx\n5qn+/6qqx4DHhstOy5UWlGfuSQ0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+\n1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNjforu0n2Az8CfgocqqqlJCcC9wA7gf3A\nx6vqjdnspqRpOppH/N+qql1VtTQs3wg8MkzLfWRYlrQA1vJU/0omU3LBabnSQhkbfgF/l+SJJNcN\n606pqlcBhu8nz2IHJU3f2Ek6F1fVK0lOBh5O8uzYDQx3FNcBnHHGGcewi5KmbdQjflW9Mnw/ANzP\nZHTWa0lOBRi+HzjM795aVUtVtbR9+/bp7LWkNTli+Enem+SX374M/A7wPeABJlNywWm50kIZ81T/\nFOD+JG9f/6+r6qEkjwP3JrkWeAm4ana7KWmajhj+MBX3/FXW/wdw6Sx2StJseeae1JDhSw0ZvtSQ\n4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDh\nSw0ZvtTQqPCTbEtyX5Jnk+xLclGSE5M8nOT54fv7Z72zkqZj7CP+l4CHquqDTP7U9j6clistrDGT\ndE4AfgO4HaCq/ruq3sRpudLCGvOIfxZwEPhKkieT3DaM0nJarrSgxoS/FfgQ8OWqugD4MUfxtD7J\ndUn2Jtl78ODBY9xNSdM0JvxlYLmq9gzL9zG5I3BarrSgjhh+Vf0AeDnJOcOqS4FncFqutLDGTMsF\n+CPgriTHAy8Cn2Jyp+G0XGkBjQq/qp4Cllb5kdNypQXkmXtSQ4YvNWT4UkOGLzVk+FJDhi81ZPhS\nQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzU0Zmjm\nOUmeWvH1VpIbHJMtLa4xk3Seq6pdVbUL+FXgv4D7cUy2tLCO9qn+pcD3q+rfcUy2tLCONvyrga8O\nl0eNyXZarrTxjA5/mJt3BfA3R7MBp+VKG8/RPOL/LvCdqnptWB41JlvSxnM04V/Dz5/mg2OypYU1\nKvwkvwTsBr6+YvXNwO4kzw8/u3n6uydpFlJV89tYchD4MfD63Da6MZxEr2PudrywcY75V6rqiG+m\nzTV8gCR7q2pprhtdZ92OudvxwuIds6fsSg0ZvtTQeoR/6zpsc711O+ZuxwsLdsxzf40vaf35VF9q\naK7hJ7ksyXNJXkiy6T7Nl+T0JI8m2Zfk6STXD+s39UeYk2xJ8mSSB4flM5PsGY73nuF0700jybYk\n9yV5dritL1q023hu4SfZAvwlk1N/zwOuSXLevLY/J4eAz1TVucCFwKeHY9zsH2G+Hti3YvnzwBeH\n430DuHZd9mp2vgQ8VFUfBM5ncuyLdRtX1Vy+gIuAb65Yvgm4aV7bX48vJqcx7waeA04d1p0KPLfe\n+zbFY9zB5H/0S4AHgTA5kWXrarf7on8BJwD/xvD+2Ir1C3Ubz/Op/mnAyyuWl4d1m1KSncAFwB5G\nfoR5Qd0CfBb42bD8AeDNqjo0LG+22/ks4CDwleHlzW1J3suC3cbzDD+rrNuU/6SQ5H3A14Abquqt\n9d6fWUlyOXCgqp5YuXqVq26m23kr8CHgy1V1AZNT0Df20/pVzDP8ZeD0Fcs7gFfmuP25SHIck+jv\nqqq3P9S0WT/CfDFwRZL9wN1Mnu7fAmxLsnW4zma7nZeB5araMyzfx+SOYKFu43mG/zhw9vCO7/FM\n/prPA3Pc/swlCXA7sK+qvrDiR5vyI8xVdVNV7aiqnUxuz29V1SeAR4GPDVfbNMcLUFU/AF5Ocs6w\n6lLgGRbsNp73p/M+wuQRYQtwR1X9xdw2PgdJfh34B+C7/Pw17+eYvM6/FzgDeAm4qqp+uC47OSNJ\nfhP4k6q6PMlZTJ4BnAg8Cfx+Vf1kPfdvmpLsAm4DjgdeBD7F5EF0YW5jz9yTGvLMPakhw5caMnyp\nIcOXGjJ8qSHDlxoyfKkhw5ca+h+ZzfhynbQeDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fc4ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = generate_rectangle(1, 0.6, 0.4, 0.4, 0.6, 40)\n",
    "plt.imshow(im.reshape(72,72), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>noise</code> parameter to the <code>generate_rectangle</code> function is actually not used. <b>Modify the function to add uniform noise to the image to make it more realistic.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Call the function below to generate a training set</b> <code> X_train, Y_train</code> <b>and a test set</b> <code> X_test, Y_test</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(nb_samples, noise):\n",
    "    X = np.ones([nb_samples,im_size])\n",
    "    Y = np.ones([nb_samples,4])\n",
    "    # We fill the array\n",
    "    for i in range(nb_samples):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        corners = np.random.random(4)\n",
    "        top = max(corners[0], corners[1])\n",
    "        bottom = min(corners[0], corners[1])\n",
    "        left = min(corners[2], corners[3])\n",
    "        right = max(corners[2], corners[3])\n",
    "        X[i] = generate_rectangle(1, top, left, bottom, right, noise)\n",
    "        Y[i,0] = top\n",
    "        Y[i,1] = left\n",
    "        Y[i,2] = bottom\n",
    "        Y[i,3] = right \n",
    "    return [X, Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization algorithms we will implement below converge better if the input values have coefficients between 0 and 1. <b>Modify</b> <code>X_train</code> and <code>X_test</code> accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the first real Machine Learning part :-)\n",
    "------------------------------------------------\n",
    "\n",
    "We want to predict from an image containing a rectangle the 4 values defining this rectangle. Since this is still a relatively simple problem, we will use linear regression of the form:\n",
    "$$\n",
    "y_\\text{pred} = x^\\top W + b\n",
    "$$\n",
    "where $x$ is the image, $W$ a matrix, $b$ a vector, and $y_\\text{pred}$ a 4-vector containing the 4 values to predict. Our goal is to learn $W$ and $b$.\n",
    "\n",
    "<b>Write the code</b> defining $x$, $W$, $b$, and $y_\\text{pred}$. $x$ should be a placeholder, $W$ and $b$ should be Variable, and $y_\\text{pred}$ should be defined as an operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function, for one sample, will be:\n",
    "$$\n",
    "\\|y_\\text{exp} - y_\\text{pred}\\|^2\n",
    "$$\n",
    "\n",
    "<b>Introduce</b> $y_\\text{exp}$ in your code (it should be a <code>placeholder</code>), and the <code>loss</code>, which should be an operation involving $y_\\text{exp}$ and $y_\\text{pred}$.\n",
    "\n",
    "Can you guess what the columns of $W$ would look like?  To optimize $W$ and $b$, we will use the following code (<b>make sure you understand it</b>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-846dbd7b7a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnb_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "batch_size = 10\n",
    "train = tf.train.GradientDescentOptimizer(0.00001).minimize(loss)\n",
    "nb_iterations = int(1e3)\n",
    "step = 10\n",
    "loss_train = np.zeros(int(nb_iterations/step))\n",
    "loss_test = np.zeros(int(nb_iterations/step))\n",
    "for i in range(nb_iterations):\n",
    "    idx = np.random.permutation(X_train.shape[0])[:batch_size]\n",
    "    feed_dict = {x:X_train[idx], y_exp:Y_train[idx]}\n",
    "    sess.run(train, feed_dict)\n",
    "    if i % step == 0:\n",
    "        loss_train[int(i/step)] = sess.run(loss, {x:X_train, y_exp:Y_train})\n",
    "        loss_test[int(i/step)] = sess.run(loss, {x:X_test, y_exp:Y_test})\n",
    "        print(\"iter:%s, loss_train:%s, loss_test:%s\" % (i, loss_train[int(i/step)]/4, loss_test[int(i/step)]/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the optimization run for several iterations. You can visualize the columns of $W$ as images with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e06b555348cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m72\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "W_array = W.eval(sess).flatten()\n",
    "fig, ax = plt.subplots(ncols=4, nrows=1,figsize=(40,10))\n",
    "for i in range(4):\n",
    "    ax[i].imshow(W_array[i::4].reshape((72,72)),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A More Difficult Problem\n",
    "========================\n",
    "\n",
    "We will now consider a problem for which linear regression is not sufficient. Our new problem is to estimate the rotation and translation for a triangle, created with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_triangle(figsize, x1, y1, x2, y2, x3, y3, noise = 0):\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    ax = fig.add_axes((0,0,1,1)) \n",
    "    plt.axis('Off')\n",
    "    ax.set_xlim(0,figsize)\n",
    "    ax.set_ylim(0,figsize)\n",
    "    ax.fill((x1, x2, x3), (y1, y2, y3), \"k\")\n",
    "    fig.canvas.draw()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')[::3].astype(np.float32)\n",
    "    data = data + noise * np.random.random(data.size)\n",
    "    plt.close(fig)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate data with the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_triangle_data(nb_samples, noise):\n",
    "    def fitting(arr):\n",
    "        for e in arr:\n",
    "            if e < 0 or e > 1:\n",
    "                return False\n",
    "        return True\n",
    "            \n",
    "    X = np.ones([nb_samples,im_size])\n",
    "    Y = np.ones([nb_samples,6])\n",
    "    # We fill the array\n",
    "    for i in range(nb_samples):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        cont = True\n",
    "        while cont:\n",
    "            (x1, y1) = np.random.random(2)\n",
    "            rot = 2 * 3.14 * np.random.random()\n",
    "            x2 = x1 + np.cos(rot) * 0.3\n",
    "            y2 = y1 + np.sin(rot) * 0.3\n",
    "            x3 = x1 - np.sin(rot) * 0.6\n",
    "            y3 = y1 + np.cos(rot) * 0.6\n",
    "            cont = not(fitting([x1, y1, x2, y2, x3, y3]))\n",
    "        X[i] = generate_triangle(1, x1, y1, x2, y2, x3, y3, noise)\n",
    "        Y[i,0] = x1\n",
    "        Y[i,1] = y1\n",
    "        Y[i,2] = x2\n",
    "        Y[i,3] = y2\n",
    "        Y[i,4] = x3\n",
    "        Y[i,5] = y3\n",
    "    return [X, Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now you are on your own!</b>  Can you modify the LeCun5 network given below to learn to predict the 3 corners of a triangle in a image?\n",
    "\n",
    "Code for LeCun5. First, make sure you understand it: This network is a convolutional neural network designed to recognized digits in 28x28 images. It is thus made for a classification problem, while we want to adapt it to a regression problem. More details are given [here](https://www.tensorflow.org/get_started/mnist/pros). You will therefore have to change:\n",
    "- the size of the input;\n",
    "- the type of the output;\n",
    "- the loss function.\n",
    "\n",
    "The rest should probably remain the same, as we can reuse the same architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "#Placeholder for the input:\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "#images are stored as vectors, we reshape them as images:\n",
    "im = tf.reshape(x, shape=[-1, 28, 28, 1])  # 28x28 = 784\n",
    "\n",
    "#32 convolutional filters and biases on the first layer:\n",
    "F1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
    "b1 = tf.Variable(tf.random_normal([32]))\n",
    "F1_im = tf.nn.conv2d(im, F1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h1 = tf.nn.relu( tf.nn.bias_add(F1_im, b1) )\n",
    "\n",
    "#Pooling on 2x2 regions:\n",
    "h2 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#Second convolutional layer: 64 5x5x32 filters:\n",
    "F3 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
    "b3 = tf.Variable(tf.random_normal([64]))\n",
    "F3_im = tf.nn.conv2d(h2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h3 = tf.nn.relu( tf.nn.bias_add(F3_im, b3) )\n",
    "\n",
    "#Second pooling layer:\n",
    "h4 = tf.nn.max_pool(h3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#First fully connected layer, 1024 output:\n",
    "h4_vect = tf.reshape(h4, [-1, 7*7*64])\n",
    "W5 = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
    "b5 = tf.Variable(tf.random_normal([1024]))\n",
    "h5 = tf.nn.relu( tf.add(tf.matmul(h4_vect, W5), b5 ))\n",
    "#h5 = tf.nn.dropout(h5, 0.75)\n",
    "\n",
    "#Second fully connected layer, 1024 input, 10 output:\n",
    "W6 = tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "b6 = tf.Variable(tf.random_normal([n_classes]))\n",
    "#Final predicted output:\n",
    "y_pred = tf.add(tf.matmul(h5, W6), b6)\n",
    "\n",
    "#Placeholder for the expected output:\n",
    "y_exp = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "#Loss:\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the output of your network with the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_prediction(x, y):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    I = x.reshape((72,72))\n",
    "    ax.imshow(I, extent=[0,1,0,1],cmap='gray')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "    xy = y.reshape(3,2)\n",
    "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
    "    ax.add_patch(tri)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and by calling this function in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d8290eb71e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "Y_test_pred = sess.run(y_pred, {x:X_test[0], y_exp:Y_test[0]})\n",
    "visualize_prediction(X_test[0], Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
